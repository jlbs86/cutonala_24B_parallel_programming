{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17ONxNo75vJN0ow51x7IqKwzDDCEXMa4e","timestamp":1728018345738}],"gpuType":"T4","authorship_tag":"ABX9TyOhisgk5ohBcCCK1deuMnck"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nTYeeMQplr8","executionInfo":{"status":"ok","timestamp":1728015209444,"user_tz":360,"elapsed":188355,"user":{"displayName":"ALAN LOPEZ CERVANTES","userId":"16779802056171643395"}},"outputId":"35b1e86c-f2e1-4efe-81bc-fdc985d9c07c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-4.0.0.tar.gz (464 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/464.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/464.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.8/464.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4266260 sha256=788df2ad2b47db703f4f289b5d85c7871a552cb4a9a84fab4df4efba97a570c8\n","  Stored in directory: /root/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-4.0.0\n"]}],"source":["! pip install mpi4py"]},{"cell_type":"code","source":[! mpiexec --oversubscribe --allow-run-as-root -n 30 python /content/pointtopoint.py\n","\n","class PointToPointCommunication:\n","  def __init__(self):\n","    self.comm = MPI.COMM_WORLD\n","    self.rank = self.comm.Get_rank()\n","    self.size = self.comm.Get_size()\n","\n","  def pickle(self):\n","    if self.rank == 0:\n","      data = {'a': 7, 'b': 3.14}\n","      self.comm.send(data, dest=1 % self.size, tag=11)\n","      print(f\"Rank {self.rank} sent data: {data}\")\n","    elif self.rank == 1:\n","      data = self.comm.recv(source=0, tag=11)\n","      print(f\"Rank {self.rank} received data: {data}\")\n","\n","  def non_blocking(self):\n","    if self.rank == 0:\n","      data = {'a': 7, 'b': 3.14}\n","      req = self.comm.isend(data, dest=1, tag=11)\n","      req.wait()\n","      print(f\"Rank {self.rank} sent data: {data}\")\n","    elif self.rank == 1:\n","      req = self.comm.irecv(source=0, tag=11)\n","      data = req.wait()\n","      print(f\"Rank {self.rank} received data: {data}\")\n","\n","  def numpy_arrays(self):\n","    if self.rank == 0:\n","      data = np.arange(1000, dtype='i')\n","      self.comm.Send([data, MPI.INT], dest=1, tag=77)\n","      print(f\"Rank {self.rank} sent data: {data}\")\n","    elif self.rank == 1:\n","      data = np.empty(1000, dtype='i')\n","      self.comm.Recv([data, MPI.INT], source=0, tag=77)\n","      print(f\"Rank {self.rank} received data: {data}\")\n","\n","    if self.rank == 0:\n","      data = np.arange(100, dtype=np.float64)\n","      self.comm.Send(data, dest=1, tag=13)\n","      print(f\"Rank {self.rank} sent data: {data}\")\n","    elif self.rank == 1:\n","      data = np.empty(100, dtype=np.float64)\n","      self.comm.Recv(data, source=0, tag=13)\n","      print(f\"Rank {self.rank} received data: {data}\")\n","\n","\n","class CollectiveCommunication:\n","  def __init__(self):\n","    self.comm = MPI.COMM_WORLD\n","    self.size = self.comm.Get_size()\n","    self.rank = self.comm.Get_rank()\n","\n","  def broadcasting(self):\n","    if self.rank == 0:\n","      data = {'key1' : [7, 2.72, 2+3j],\n","              'key2' : ( 'abc', 'xyz')}\n","    else:\n","        data = None\n","    data = self.comm.bcast(data, root=0)\n","    print(f\"Rank {self.rank} received data: {data}\")\n","\n","  def scattering(self):\n","    if self.rank == 0:\n","      data = [(i+1)**2 for i in range(self.size)]\n","    else:\n","        data = None\n","    data = self.comm.scatter(data, root=0)\n","    assert data == (self.rank+1)**2\n","    print(f\"Rank {self.rank} received data: {data}\")\n","\n","  def gathering(self):\n","    data = (self.rank+1)**2\n","    data = self.comm.gather(data, root=0)\n","    if self.rank == 0:\n","      for i in range(self.size):\n","        assert data[i] == (i+1)**2\n","      print(f\"Rank {self.rank} gathered data: {data}\")\n","    else:\n","      assert data is None\n","      print(f\"Rank {self.rank} sent data: {(self.rank+1)**2}\")\n","\n","  def broadcasting_numpy(self):\n","    if self.rank == 0:\n","      data = np.arange(100, dtype='i')\n","    else:\n","      data = np.empty(100, dtype='i')\n","    self.comm.Bcast(data, root=0)\n","    for i in range(100):\n","        assert data[i] == i\n","    print(f\"Rank {self.rank} received data: {data}\")\n","\n","  def scattering_numpy(self):\n","    sendbuf = None\n","    if self.rank == 0:\n","      sendbuf = np.empty([self.size, 100], dtype='i')\n","      sendbuf.T[:,:] = range(self.size)\n","    recvbuf = np.empty(100, dtype='i')\n","    self.comm.Scatter(sendbuf, recvbuf, root=0)\n","    assert np.allclose(recvbuf, self.rank)\n","    print(f\"Rank {self.rank} received data: {recvbuf}\")\n","\n","  def gathering_numpy(self):\n","    sendbuf = np.zeros(100, dtype='i') + self.rank\n","    recvbuf = None\n","    if self.rank == 0:\n","      recvbuf = np.empty([self.size, 100], dtype='i')\n","    self.comm.Gather(sendbuf, recvbuf, root=0)\n","    if self.rank == 0:\n","      for i in range(self.size):\n","        assert np.allclose(recvbuf[i,:], i)\n","      print(f\"Rank {self.rank} gathered data: {recvbuf}\")\n","    else:\n","      print(f\"Rank {self.rank} sent data: {sendbuf}\")\n","\n","  def parallel_matrix(self, comm, A, x, m):\n","    m = A.shape[0] # local rows\n","    p = comm.Get_size()\n","    xg = np.zeros(m*p, dtype='d')\n","    comm.Allgather([x,  MPI.DOUBLE],\n","                   [xg, MPI.DOUBLE])\n","    y = np.dot(A, xg)\n","    return y\n","\n","if __name__ == '__main__':\n","    ptp_comm = PointToPointCommunication()\n","    coll_comm = CollectiveCommunication()\n","    ptp_comm.pickle()"],"metadata":{"id":"93fEaiQmqvHj","executionInfo":{"status":"ok","timestamp":1728018303149,"user_tz":360,"elapsed":326,"user":{"displayName":"ALAN LOPEZ CERVANTES","userId":"16779802056171643395"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74fc57b0-20f8-482b-86b4-acac1b2eaa1d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Rank 0 sent data: {'a': 7, 'b': 3.14}\n"]}]},{"source":[],"cell_type":"code","metadata":{"id":"A-yz6F6m2-Y0"},"execution_count":null,"outputs":[]}]}
