{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtYB3F0C4QNf33ZGM2MpfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlbs86/cutonala_24B_parallel_programming/blob/HAGC_Task_mpi4py_library/mpi4py_library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0mIOJGnzHXQ",
        "outputId": "f1a9afc7-c72c-4e72-f520-d9545fee60c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Using cached mpi4py-4.0.0.tar.gz (464 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4266267 sha256=a7d2ce330835e56f49223f94d3149cae261aa152a653d48fe3ad01b7105c7c71\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.0\n"
          ]
        }
      ],
      "source": [
        "! pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpiexec --oversubscribe --allow-run-as-root -n 4 python /content/sample_data/example.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfaLLxM1BlYu",
        "outputId": "9b07a934-0481-4335-ce66-8b424b41c256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 0 received data: {'a': 7, 'b': 3.14}\n",
            "Rank 1 received data: {'a': 7, 'b': 3.14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an example.py file in the sample_data folder and copy the following code:"
      ],
      "metadata": {
        "id": "rfN_S3-2k0YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "\n",
        "# Point-to-Point Communication class\n",
        "class PointToPointCommunication:\n",
        "  def __init__(self):\n",
        "    self.comm = MPI.COMM_WORLD\n",
        "    self.rank = self.comm.Get_rank()\n",
        "\n",
        "  # Method for sending and receiving data using pickle\n",
        "  def spickle_data_communication(self):\n",
        "    if self.rank == 0:\n",
        "      data = {'a': 7, 'b': 3.14}\n",
        "      self.comm.send(data, dest=1, tag=11)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "    elif self.rank == 1:\n",
        "      data = self.comm.recv(source=0, tag=11)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "  # Method for non-blocking communication\n",
        "  def non_block_communication(self):\n",
        "    if self.rank == 0:\n",
        "      data = {'a': 7, 'b': 3.14}\n",
        "      req = self.comm.isend(data, dest=1, tag=11)\n",
        "      req.wait()\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "    elif self.rank == 1:\n",
        "      req = self.comm.irecv(source=0, tag=11)\n",
        "      data = req.wait()\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "  # Method for sending and receiving numpy arrays\n",
        "  def numpy_arrays(self):\n",
        "    # passing MPI datatypes explicitly\n",
        "    if self.rank == 0:\n",
        "      data = np.arange(1000, dtype='i')\n",
        "      self.comm.Send([data, MPI.INT], dest=1, tag=77)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "    elif self.rank == 1:\n",
        "      data = np.empty(1000, dtype='i')\n",
        "      self.comm.Recv([data, MPI.INT], source=0, tag=77)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "    # automatic MPI datatype discovery\n",
        "    if self.rank == 0:\n",
        "      data = np.arange(100, dtype=np.float64)\n",
        "      self.comm.Send(data, dest=1, tag=13)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "    elif self.rank == 1:\n",
        "      data = np.empty(100, dtype=np.float64)\n",
        "      self.comm.Recv(data, source=0, tag=13)\n",
        "      print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "# Collective Communication class\n",
        "class CollectiveCommunication:\n",
        "  def __init__(self):\n",
        "    self.comm = MPI.COMM_WORLD\n",
        "    self.size = self.comm.Get_size()\n",
        "    self.rank = self.comm.Get_rank()\n",
        "\n",
        "  # Method for broadcasting a dictionary\n",
        "  def broadcast_dict(self):\n",
        "    if self.rank == 0:\n",
        "      data = {'key1' : [7, 2.72, 2+3j],\n",
        "              'key2' : ( 'abc', 'xyz')}\n",
        "    else:\n",
        "        data = None\n",
        "    data = self.comm.bcast(data, root=0)\n",
        "    print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "  # Method for scattering objects\n",
        "  def scatter_objects(self):\n",
        "    if self.rank == 0:\n",
        "      data = [(i+1)**2 for i in range(self.size)]\n",
        "    else:\n",
        "        data = None\n",
        "    data = self.comm.scatter(data, root=0)\n",
        "    assert data == (self.rank+1)**2\n",
        "    print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "  # Method for gathering objects\n",
        "  def gather_objects(self):\n",
        "    data = (self.rank+1)**2\n",
        "    data = self.comm.gather(data, root=0)\n",
        "    if self.rank == 0:\n",
        "      for i in range(self.size):\n",
        "        assert data[i] == (i+1)**2\n",
        "      print(f\"Rank {self.rank} gathered data: {data}\")\n",
        "    else:\n",
        "      assert data is None\n",
        "      print(f\"Rank {self.rank} sent data: {(self.rank+1)**2}\")\n",
        "\n",
        "  # Method for broadcasting numpy arrays\n",
        "  def broadcast_numpy_arrays(self):\n",
        "    if self.rank == 0:\n",
        "      data = np.arange(100, dtype='i')\n",
        "    else:\n",
        "      data = np.empty(100, dtype='i')\n",
        "    self.comm.Bcast(data, root=0)\n",
        "    for i in range(100):\n",
        "        assert data[i] == i\n",
        "    print(f\"Rank {self.rank} received data: {data}\")\n",
        "\n",
        "  # Method for scattering numpy arrays\n",
        "  def scatter_numpy_arrays(self):\n",
        "    sendbuf = None\n",
        "    if self.rank == 0:\n",
        "      sendbuf = np.empty([self.size, 100], dtype='i')\n",
        "      sendbuf.T[:,:] = range(self.size)\n",
        "    recvbuf = np.empty(100, dtype='i')\n",
        "    self.comm.Scatter(sendbuf, recvbuf, root=0)\n",
        "    assert np.allclose(recvbuf, self.rank)\n",
        "    print(f\"Rank {self.rank} received data: {recvbuf}\")\n",
        "\n",
        "  # Method for gathering numpy arrays\n",
        "  def gather_numpy_arrays(self):\n",
        "    sendbuf = np.zeros(100, dtype='i') + self.rank\n",
        "    recvbuf = None\n",
        "    if self.rank == 0:\n",
        "      recvbuf = np.empty([self.size, 100], dtype='i')\n",
        "    self.comm.Gather(sendbuf, recvbuf, root=0)\n",
        "    if self.rank == 0:\n",
        "      for i in range(self.size):\n",
        "        assert np.allclose(recvbuf[i,:], i)\n",
        "      print(f\"Rank {self.rank} gathered data: {recvbuf}\")\n",
        "    else:\n",
        "      print(f\"Rank {self.rank} sent data: {sendbuf}\")\n",
        "\n",
        "  # Method for parallel matrix-vector product\n",
        "  def parallel_matrix_vector_product(self, comm, A, x, m):\n",
        "    m = A.shape[0] # local rows\n",
        "    p = comm.Get_size()\n",
        "    xg = np.zeros(m*p, dtype='d')\n",
        "    comm.Allgather([x,  MPI.DOUBLE],\n",
        "                   [xg, MPI.DOUBLE])\n",
        "    y = np.dot(A, xg)\n",
        "    return y\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ptp_comm = PointToPointCommunication()\n",
        "    coll_comm = CollectiveCommunication()\n",
        "\n",
        "    '''\n",
        "      Call point-to-point communication methods:\n",
        "        Point-to-Point Communication\n",
        "        Non-blocking Communication\n",
        "        Numpy Arrays Communication\n",
        "    '''\n",
        "    ptp_comm.spickle_data_communication()\n",
        "    # ptp_comm.non_block_communication()\n",
        "    # ptp_comm.numpy_arrays()\n",
        "\n",
        "    '''\n",
        "      Call collective communication methods:\n",
        "        Collective Communication\n",
        "        Scatter Objects\n",
        "        Gather Objects\n",
        "        Broadcast Numpy Arrays\n",
        "        Scatter Numpy Arrays\n",
        "        Gather Numpy Arrays\n",
        "    '''\n",
        "    # coll_comm.broadcast_dict()\n",
        "    # coll_comm.scatter_objects()\n",
        "    # coll_comm.gather_objects()\n",
        "    # coll_comm.broadcast_numpy_arrays()\n",
        "    # coll_comm.scatter_numpy_arrays()\n",
        "    # coll_comm.gather_numpy_arrays()\n"
      ],
      "metadata": {
        "id": "-tXILyPNlE5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}